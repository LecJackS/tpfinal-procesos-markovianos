{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:36:24.857033Z",
     "start_time": "2019-06-22T14:36:24.839033Z"
    }
   },
   "source": [
    "Story so far:\n",
    "\n",
    "Hasta el aproximador lineal todo fue bastante agradable.\n",
    "\n",
    "A la hora de implementar la red neuronal me topé con:\n",
    "* los estados (mapa+score) están en ascii < a la NN no le gusta ésto\n",
    "* Después de mil quilombos de tipos, la NN conecta con el agente\n",
    "* PERO parece no aprender nada\n",
    "  * Posibles causas: \n",
    "    * a. updateo mal los weights (sospecho que es en la derivada parcial con respecto a $\\hat{q}(S,A)$)\n",
    "    * b. tarda mucho en aprender algo que sirva (al principio)\n",
    "    * c. la estructura de la NN es una chota\n",
    "  * Solución\n",
    "    1. Grabar un par de juegos con el aprox lineal\n",
    "    2. Usar Sup.Learning para aproximar una función a los juegos guardados (no online learning)\n",
    "    3. Si puedo overfitear con la misma NN, entonces puede aprender online, sino no\n",
    "    4. Si se cumple 3., puedo:\n",
    "       * descartar c.\n",
    "       * inicializar weights con lo aprendido, y también descartar b.\n",
    "    \n",
    "En el medio me encontré con que:\n",
    "* no se guardaban bien los juegos porque usaron codigo de python 2 con pickle y no lo updatearon.\n",
    "* Dependencias circulares (imports mutuos) entre un par de archivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:36:24.872828Z",
     "start_time": "2019-06-22T14:36:24.858647Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T14:36:24.898906Z",
     "start_time": "2019-06-22T14:36:24.877122Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T03:50:16.118745Z",
     "start_time": "2019-06-23T03:50:16.116405Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Licensing Information: You are free to use or extend these projects for\n",
    "# educational purposes provided that (1) you do not distribute or publish\n",
    "# solutions, (2) you retain this notice, and (3) you provide clear\n",
    "# attribution to UC Berkeley, including a link to http://ai.berkeley.edu.\n",
    "#\n",
    "# Attribution Information: The Pacman AI projects were developed at UC Berkeley.\n",
    "# The core projects and autograders were primarily created by John DeNero\n",
    "# (denero@cs.berkeley.edu) and Dan Klein (klein@cs.berkeley.edu).\n",
    "# Student side autograding was added by Brad Miller, Nick Hay, and\n",
    "# Pieter Abbeel (pabbeel@cs.berkeley.edu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T03:50:16.123522Z",
     "start_time": "2019-06-23T03:50:16.120868Z"
    }
   },
   "outputs": [],
   "source": [
    "## for testing\n",
    "SOME_GLOBAL_STATE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T03:50:16.377383Z",
     "start_time": "2019-06-23T03:50:16.126030Z"
    },
    "code_folding": [
     2,
     329,
     389,
     475,
     479,
     493,
     615,
     643,
     664
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from game.ipynb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pacman.py holds the logic for the classic pacman game along with the main\n",
    "code to run a game.  This file is divided into three sections:\n",
    "\n",
    "  (i)  Your interface to the pacman world:\n",
    "          Pacman is a complex environment.  You probably don't want to\n",
    "          read through all of the code we wrote to make the game runs\n",
    "          correctly.  This section contains the parts of the code\n",
    "          that you will need to understand in order to complete the\n",
    "          project.  There is also some code in game.py that you should\n",
    "          understand.\n",
    "\n",
    "  (ii)  The hidden secrets of pacman:\n",
    "          This section contains all of the logic code that the pacman\n",
    "          environment uses to decide who can move where, who dies when\n",
    "          things collide, etc.  You shouldn't need to read this section\n",
    "          of code, but you can if you want.\n",
    "\n",
    "  (iii) Framework to start a game:\n",
    "          The final section contains the code for reading the command\n",
    "          you use to set up the game, then starting up a new game, along with\n",
    "          linking in all the external parts (agent functions, graphics).\n",
    "          Check this section out to see all the options available to you.\n",
    "\"\"\"\n",
    "\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "from game import GameStateData\n",
    "from game import Game\n",
    "from game import Directions\n",
    "from game import Actions\n",
    "from util import nearestPoint\n",
    "from util import manhattanDistance\n",
    "import util\n",
    "import layout\n",
    "import sys\n",
    "import types\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "###################################################\n",
    "# YOUR INTERFACE TO THE PACMAN WORLD: A GameState #\n",
    "###################################################\n",
    "\n",
    "\n",
    "class GameState:\n",
    "    \"\"\"\n",
    "    A GameState specifies the full game state, including the food, capsules,\n",
    "    agent configurations and score changes.\n",
    "\n",
    "    GameStates are used by the Game object to capture the actual state of the game and\n",
    "    can be used by agents to reason about the game.\n",
    "\n",
    "    Much of the information in a GameState is stored in a GameStateData object.  We\n",
    "    strongly suggest that you access that data via the accessor methods below rather\n",
    "    than referring to the GameStateData object directly.\n",
    "\n",
    "    Note that in classic Pacman, Pacman is always agent 0.\n",
    "    \"\"\"\n",
    "\n",
    "    ####################################################\n",
    "    # Accessor methods: use these to access state data #\n",
    "    ####################################################\n",
    "\n",
    "    # static variable keeps track of which states have had getLegalActions called\n",
    "    explored = set()\n",
    "\n",
    "    def getAndResetExplored():\n",
    "        tmp = GameState.explored.copy()\n",
    "        GameState.explored = set()\n",
    "        return tmp\n",
    "    getAndResetExplored = staticmethod(getAndResetExplored)\n",
    "\n",
    "    def getLegalActions(self, agentIndex=0):\n",
    "        \"\"\"\n",
    "        Returns the legal actions for the agent specified.\n",
    "        \"\"\"\n",
    "#        GameState.explored.add(self)\n",
    "        if self.isWin() or self.isLose():\n",
    "            return []\n",
    "\n",
    "        if agentIndex == 0:  # Pacman is moving\n",
    "            return PacmanRules.getLegalActions(self)\n",
    "        else:\n",
    "            return GhostRules.getLegalActions(self, agentIndex)\n",
    "\n",
    "    def generateSuccessor(self, agentIndex, action):\n",
    "        \"\"\"\n",
    "        Returns the successor state after the specified agent takes the action.\n",
    "        \"\"\"\n",
    "        # Check that successors exist\n",
    "        if self.isWin() or self.isLose():\n",
    "            raise Exception('Can\\'t generate a successor of a terminal state.')\n",
    "\n",
    "        # Copy current state\n",
    "        state = GameState(self)\n",
    "\n",
    "        # Let agent's logic deal with its action's effects on the board\n",
    "        if agentIndex == 0:  # Pacman is moving\n",
    "            state.data._eaten = [False for i in range(state.getNumAgents())]\n",
    "            PacmanRules.applyAction(state, action)\n",
    "        else:                # A ghost is moving\n",
    "            GhostRules.applyAction(state, action, agentIndex)\n",
    "\n",
    "        # Time passes\n",
    "        if agentIndex == 0:\n",
    "            state.data.scoreChange += -TIME_PENALTY  # Penalty for waiting around\n",
    "        else:\n",
    "            GhostRules.decrementTimer(state.data.agentStates[agentIndex])\n",
    "\n",
    "        # Resolve multi-agent effects\n",
    "        GhostRules.checkDeath(state, agentIndex)\n",
    "\n",
    "        # Book keeping\n",
    "        state.data._agentMoved = agentIndex\n",
    "        state.data.score += state.data.scoreChange\n",
    "        GameState.explored.add(self)\n",
    "        GameState.explored.add(state)\n",
    "        return state\n",
    "\n",
    "    def getLegalPacmanActions(self):\n",
    "        return self.getLegalActions(0)\n",
    "\n",
    "    def generatePacmanSuccessor(self, action):\n",
    "        \"\"\"\n",
    "        Generates the successor state after the specified pacman move\n",
    "        \"\"\"\n",
    "        return self.generateSuccessor(0, action)\n",
    "\n",
    "    def getPacmanState(self):\n",
    "        \"\"\"\n",
    "        Returns an AgentState object for pacman (in game.py)\n",
    "\n",
    "        state.pos gives the current position\n",
    "        state.direction gives the travel vector\n",
    "        \"\"\"\n",
    "        return self.data.agentStates[0].copy()\n",
    "\n",
    "    def getPacmanPosition(self):\n",
    "        return self.data.agentStates[0].getPosition()\n",
    "\n",
    "    def getGhostStates(self):\n",
    "        return self.data.agentStates[1:]\n",
    "\n",
    "    def getGhostState(self, agentIndex):\n",
    "        if agentIndex == 0 or agentIndex >= self.getNumAgents():\n",
    "            raise Exception(\"Invalid index passed to getGhostState\")\n",
    "        return self.data.agentStates[agentIndex]\n",
    "\n",
    "    def getGhostPosition(self, agentIndex):\n",
    "        if agentIndex == 0:\n",
    "            raise Exception(\"Pacman's index passed to getGhostPosition\")\n",
    "        return self.data.agentStates[agentIndex].getPosition()\n",
    "\n",
    "    def getGhostPositions(self):\n",
    "        return [s.getPosition() for s in self.getGhostStates()]\n",
    "\n",
    "    def getNumAgents(self):\n",
    "        return len(self.data.agentStates)\n",
    "\n",
    "    def getScore(self):\n",
    "        return float(self.data.score)\n",
    "\n",
    "    def getCapsules(self):\n",
    "        \"\"\"\n",
    "        Returns a list of positions (x,y) of the remaining capsules.\n",
    "        \"\"\"\n",
    "        return self.data.capsules\n",
    "\n",
    "    def getNumFood(self):\n",
    "        return self.data.food.count()\n",
    "\n",
    "    def getFood(self):\n",
    "        \"\"\"\n",
    "        Returns a Grid of boolean food indicator variables.\n",
    "\n",
    "        Grids can be accessed via list notation, so to check\n",
    "        if there is food at (x,y), just call\n",
    "\n",
    "        currentFood = state.getFood()\n",
    "        if currentFood[x][y] == True: ...\n",
    "        \"\"\"\n",
    "        return self.data.food\n",
    "\n",
    "    def getWalls(self):\n",
    "        \"\"\"\n",
    "        Returns a Grid of boolean wall indicator variables.\n",
    "\n",
    "        Grids can be accessed via list notation, so to check\n",
    "        if there is a wall at (x,y), just call\n",
    "\n",
    "        walls = state.getWalls()\n",
    "        if walls[x][y] == True: ...\n",
    "        \"\"\"\n",
    "        return self.data.layout.walls\n",
    "\n",
    "    def hasFood(self, x, y):\n",
    "        return self.data.food[x][y]\n",
    "\n",
    "    def hasWall(self, x, y):\n",
    "        return self.data.layout.walls[x][y]\n",
    "\n",
    "    def isLose(self):\n",
    "        return self.data._lose\n",
    "\n",
    "    def isWin(self):\n",
    "        return self.data._win\n",
    "\n",
    "    #############################################\n",
    "    #             Helper methods:               #\n",
    "    # You shouldn't need to call these directly #\n",
    "    #############################################\n",
    "\n",
    "    def __init__(self, prevState=None):\n",
    "        \"\"\"\n",
    "        Generates a new state by copying information from its predecessor.\n",
    "        \"\"\"\n",
    "        if prevState != None:  # Initial state\n",
    "            self.data = GameStateData(prevState.data)\n",
    "        else:\n",
    "            self.data = GameStateData()\n",
    "\n",
    "    def deepCopy(self):\n",
    "        state = GameState(self)\n",
    "        state.data = self.data.deepCopy()\n",
    "        return state\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Allows two states to be compared.\n",
    "        \"\"\"\n",
    "        return hasattr(other, 'data') and self.data == other.data\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Allows states to be keys of dictionaries.\n",
    "        \"\"\"\n",
    "        return hash(self.data)\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        return str(self.data)\n",
    "\n",
    "    def initialize(self, layout, numGhostAgents=1000):\n",
    "        \"\"\"\n",
    "        Creates an initial game state from a layout array (see layout.py).\n",
    "        \"\"\"\n",
    "        self.data.initialize(layout, numGhostAgents)\n",
    "\n",
    "############################################################################\n",
    "#                     THE HIDDEN SECRETS OF PACMAN                         #\n",
    "#                                                                          #\n",
    "# You shouldn't need to look through the code in this section of the file. #\n",
    "############################################################################\n",
    "\n",
    "\n",
    "SCARED_TIME = 40    # Moves ghosts are scared\n",
    "COLLISION_TOLERANCE = 0.7  # How close ghosts must be to Pacman to kill\n",
    "TIME_PENALTY = 1  # Number of points lost each round\n",
    "\n",
    "\n",
    "class ClassicGameRules:\n",
    "    \"\"\"\n",
    "    These game rules manage the control flow of a game, deciding when\n",
    "    and how the game starts and ends.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, timeout=30):\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def newGame(self, layout, pacmanAgent, ghostAgents, display, quiet=False, catchExceptions=False):\n",
    "        agents = [pacmanAgent] + ghostAgents[:layout.getNumGhosts()]\n",
    "        initState = GameState()\n",
    "        initState.initialize(layout, len(ghostAgents))\n",
    "        game = Game(agents, display, self, catchExceptions=catchExceptions)\n",
    "        game.state = initState\n",
    "        self.initialState = initState.deepCopy()\n",
    "        self.quiet = quiet\n",
    "        return game\n",
    "\n",
    "    def process(self, state, game):\n",
    "        \"\"\"\n",
    "        Checks to see whether it is time to end the game.\n",
    "        \"\"\"\n",
    "        \n",
    "#         print(\"state2:\", len(str(state)), np.asarray(str(state)).flatten()) #--------------------------------------------<\n",
    "        global SOME_GLOBAL_STATE \n",
    "        SOME_GLOBAL_STATE = state\n",
    "        \n",
    "        if state.isWin():\n",
    "            self.win(state, game)\n",
    "        if state.isLose():\n",
    "            self.lose(state, game)\n",
    "\n",
    "    def win(self, state, game):\n",
    "        if not self.quiet:\n",
    "            print(\"Pacman emerges victorious! Score: %d\" % state.data.score)\n",
    "        game.gameOver = True\n",
    "\n",
    "    def lose(self, state, game):\n",
    "        if not self.quiet:\n",
    "            print(\"Pacman died! Score: %d\" % state.data.score)\n",
    "        game.gameOver = True\n",
    "\n",
    "    def getProgress(self, game):\n",
    "        return float(game.state.getNumFood()) / self.initialState.getNumFood()\n",
    "\n",
    "    def agentCrash(self, game, agentIndex):\n",
    "        if agentIndex == 0:\n",
    "            print(\"Pacman crashed\")\n",
    "        else:\n",
    "            print(\"A ghost crashed\")\n",
    "\n",
    "    def getMaxTotalTime(self, agentIndex):\n",
    "        return self.timeout\n",
    "\n",
    "    def getMaxStartupTime(self, agentIndex):\n",
    "        return self.timeout\n",
    "\n",
    "    def getMoveWarningTime(self, agentIndex):\n",
    "        return self.timeout\n",
    "\n",
    "    def getMoveTimeout(self, agentIndex):\n",
    "        return self.timeout\n",
    "\n",
    "    def getMaxTimeWarnings(self, agentIndex):\n",
    "        return 0\n",
    "\n",
    "\n",
    "class PacmanRules:\n",
    "    \"\"\"\n",
    "    These functions govern how pacman interacts with his environment under\n",
    "    the classic game rules.\n",
    "    \"\"\"\n",
    "    PACMAN_SPEED = 1\n",
    "\n",
    "    def getLegalActions(state):\n",
    "        \"\"\"\n",
    "        Returns a list of possible actions.\n",
    "        \"\"\"\n",
    "        return Actions.getPossibleActions(state.getPacmanState().configuration, state.data.layout.walls)\n",
    "    getLegalActions = staticmethod(getLegalActions)\n",
    "\n",
    "    def applyAction(state, action):\n",
    "        \"\"\"\n",
    "        Edits the state to reflect the results of the action.\n",
    "        \"\"\"\n",
    "        legal = PacmanRules.getLegalActions(state)\n",
    "        if action not in legal:\n",
    "            raise Exception(\"Illegal action \" + str(action))\n",
    "\n",
    "        pacmanState = state.data.agentStates[0]\n",
    "\n",
    "        # Update Configuration\n",
    "        vector = Actions.directionToVector(action, PacmanRules.PACMAN_SPEED)\n",
    "        pacmanState.configuration = pacmanState.configuration.generateSuccessor(\n",
    "            vector)\n",
    "\n",
    "        # Eat\n",
    "        next = pacmanState.configuration.getPosition()\n",
    "        nearest = nearestPoint(next)\n",
    "        if manhattanDistance(nearest, next) <= 0.5:\n",
    "            # Remove food\n",
    "            PacmanRules.consume(nearest, state)\n",
    "    applyAction = staticmethod(applyAction)\n",
    "\n",
    "    def consume(position, state):\n",
    "        x, y = position\n",
    "        # Eat food\n",
    "        if state.data.food[x][y]:\n",
    "            state.data.scoreChange += 10\n",
    "            state.data.food = state.data.food.copy()\n",
    "            state.data.food[x][y] = False\n",
    "            state.data._foodEaten = position\n",
    "            # TODO: cache numFood?\n",
    "            numFood = state.getNumFood()\n",
    "            if numFood == 0 and not state.data._lose:\n",
    "                state.data.scoreChange += 500\n",
    "                state.data._win = True\n",
    "        # Eat capsule\n",
    "        if(position in state.getCapsules()):\n",
    "            state.data.capsules.remove(position)\n",
    "            state.data._capsuleEaten = position\n",
    "            # Reset all ghosts' scared timers\n",
    "            for index in range(1, len(state.data.agentStates)):\n",
    "                state.data.agentStates[index].scaredTimer = SCARED_TIME\n",
    "    consume = staticmethod(consume)\n",
    "\n",
    "\n",
    "class GhostRules:\n",
    "    \"\"\"\n",
    "    These functions dictate how ghosts interact with their environment.\n",
    "    \"\"\"\n",
    "    GHOST_SPEED = 1.0\n",
    "\n",
    "    def getLegalActions(state, ghostIndex):\n",
    "        \"\"\"\n",
    "        Ghosts cannot stop, and cannot turn around unless they\n",
    "        reach a dead end, but can turn 90 degrees at intersections.\n",
    "        \"\"\"\n",
    "        conf = state.getGhostState(ghostIndex).configuration\n",
    "        possibleActions = Actions.getPossibleActions(\n",
    "            conf, state.data.layout.walls)\n",
    "        reverse = Actions.reverseDirection(conf.direction)\n",
    "        if Directions.STOP in possibleActions:\n",
    "            possibleActions.remove(Directions.STOP)\n",
    "        if reverse in possibleActions and len(possibleActions) > 1:\n",
    "            possibleActions.remove(reverse)\n",
    "        return possibleActions\n",
    "    getLegalActions = staticmethod(getLegalActions)\n",
    "\n",
    "    def applyAction(state, action, ghostIndex):\n",
    "\n",
    "        legal = GhostRules.getLegalActions(state, ghostIndex)\n",
    "        if action not in legal:\n",
    "            raise Exception(\"Illegal ghost action \" + str(action))\n",
    "\n",
    "        ghostState = state.data.agentStates[ghostIndex]\n",
    "        speed = GhostRules.GHOST_SPEED\n",
    "        if ghostState.scaredTimer > 0:\n",
    "            speed /= 2.0\n",
    "        vector = Actions.directionToVector(action, speed)\n",
    "        ghostState.configuration = ghostState.configuration.generateSuccessor(\n",
    "            vector)\n",
    "    applyAction = staticmethod(applyAction)\n",
    "\n",
    "    def decrementTimer(ghostState):\n",
    "        timer = ghostState.scaredTimer\n",
    "        if timer == 1:\n",
    "            ghostState.configuration.pos = nearestPoint(\n",
    "                ghostState.configuration.pos)\n",
    "        ghostState.scaredTimer = max(0, timer - 1)\n",
    "    decrementTimer = staticmethod(decrementTimer)\n",
    "\n",
    "    def checkDeath(state, agentIndex):\n",
    "        pacmanPosition = state.getPacmanPosition()\n",
    "        if agentIndex == 0:  # Pacman just moved; Anyone can kill him\n",
    "            for index in range(1, len(state.data.agentStates)):\n",
    "                ghostState = state.data.agentStates[index]\n",
    "                ghostPosition = ghostState.configuration.getPosition()\n",
    "                if GhostRules.canKill(pacmanPosition, ghostPosition):\n",
    "                    GhostRules.collide(state, ghostState, index)\n",
    "        else:\n",
    "            ghostState = state.data.agentStates[agentIndex]\n",
    "            ghostPosition = ghostState.configuration.getPosition()\n",
    "            if GhostRules.canKill(pacmanPosition, ghostPosition):\n",
    "                GhostRules.collide(state, ghostState, agentIndex)\n",
    "    checkDeath = staticmethod(checkDeath)\n",
    "\n",
    "    def collide(state, ghostState, agentIndex):\n",
    "        if ghostState.scaredTimer > 0:\n",
    "            state.data.scoreChange += 200\n",
    "            GhostRules.placeGhost(state, ghostState)\n",
    "            ghostState.scaredTimer = 0\n",
    "            # Added for first-person\n",
    "            state.data._eaten[agentIndex] = True\n",
    "        else:\n",
    "            if not state.data._win:\n",
    "                state.data.scoreChange -= 500\n",
    "                state.data._lose = True\n",
    "    collide = staticmethod(collide)\n",
    "\n",
    "    def canKill(pacmanPosition, ghostPosition):\n",
    "        return manhattanDistance(ghostPosition, pacmanPosition) <= COLLISION_TOLERANCE\n",
    "    canKill = staticmethod(canKill)\n",
    "\n",
    "    def placeGhost(state, ghostState):\n",
    "        ghostState.configuration = ghostState.start\n",
    "    placeGhost = staticmethod(placeGhost)\n",
    "\n",
    "#############################\n",
    "# FRAMEWORK TO START A GAME #\n",
    "#############################\n",
    "\n",
    "\n",
    "def default(str):\n",
    "    return str + ' [Default: %default]'\n",
    "\n",
    "\n",
    "def parseAgentArgs(str):\n",
    "    if str == None:\n",
    "        return {}\n",
    "    pieces = str.split(',')\n",
    "    opts = {}\n",
    "    for p in pieces:\n",
    "        if '=' in p:\n",
    "            key, val = p.split('=')\n",
    "        else:\n",
    "            key, val = p, 1\n",
    "        opts[key] = val\n",
    "    return opts\n",
    "\n",
    "\n",
    "def readCommand(argv):\n",
    "    \"\"\"\n",
    "    Processes the command used to run pacman from the command line.\n",
    "    \"\"\"\n",
    "    from optparse import OptionParser\n",
    "    usageStr = \"\"\"\n",
    "    USAGE:      python pacman.py <options>\n",
    "    EXAMPLES:   (1) python pacman.py\n",
    "                    - starts an interactive game\n",
    "                (2) python pacman.py --layout smallClassic --zoom 2\n",
    "                OR  python pacman.py -l smallClassic -z 2\n",
    "                    - starts an interactive game on a smaller board, zoomed in\n",
    "    \"\"\"\n",
    "    parser = OptionParser(usageStr)\n",
    "\n",
    "    parser.add_option('-n', '--numGames', dest='numGames', type='int',\n",
    "                      help=default('the number of GAMES to play'), metavar='GAMES', default=1)\n",
    "    parser.add_option('-l', '--layout', dest='layout',\n",
    "                      help=default(\n",
    "                          'the LAYOUT_FILE from which to load the map layout'),\n",
    "                      metavar='LAYOUT_FILE', default='mediumClassic')\n",
    "    parser.add_option('-p', '--pacman', dest='pacman',\n",
    "                      help=default(\n",
    "                          'the agent TYPE in the pacmanAgents module to use'),\n",
    "                      metavar='TYPE', default='KeyboardAgent')\n",
    "    parser.add_option('-t', '--textGraphics', action='store_true', dest='textGraphics',\n",
    "                      help='Display output as text only', default=False)\n",
    "    parser.add_option('-q', '--quietTextGraphics', action='store_true', dest='quietGraphics',\n",
    "                      help='Generate minimal output and no graphics', default=False)\n",
    "    parser.add_option('-g', '--ghosts', dest='ghost',\n",
    "                      help=default(\n",
    "                          'the ghost agent TYPE in the ghostAgents module to use'),\n",
    "                      metavar='TYPE', default='RandomGhost')\n",
    "    parser.add_option('-k', '--numghosts', type='int', dest='numGhosts',\n",
    "                      help=default('The maximum number of ghosts to use'), default=4)\n",
    "    parser.add_option('-z', '--zoom', type='float', dest='zoom',\n",
    "                      help=default('Zoom the size of the graphics window'), default=1.0)\n",
    "    parser.add_option('-f', '--fixRandomSeed', action='store_true', dest='fixRandomSeed',\n",
    "                      help='Fixes the random seed to always play the same game', default=False)\n",
    "    parser.add_option('-r', '--recordActions', action='store_true', dest='record',\n",
    "                      help='Writes game histories to a file (named by the time they were played)',\n",
    "                      default=False)\n",
    "    parser.add_option('--replay', dest='gameToReplay',\n",
    "                      help='A recorded game file (pickle) to replay',\n",
    "                      default=None)\n",
    "                      #default=\"recorded/recorded-game-326-22-10-59-19\")\n",
    "    parser.add_option('-a', '--agentArgs', dest='agentArgs',\n",
    "                      help='Comma separated values sent to agent. e.g. \"opt1=val1,opt2,opt3=val3\"')\n",
    "    parser.add_option('-x', '--numTraining', dest='numTraining', type='int',\n",
    "                      help=default('How many episodes are training (suppresses output)'), default=0)\n",
    "    parser.add_option('--frameTime', dest='frameTime', type='float',\n",
    "                      help=default('Time to delay between frames; <0 means keyboard'), default=0.1)\n",
    "    parser.add_option('-c', '--catchExceptions', action='store_true', dest='catchExceptions',\n",
    "                      help='Turns on exception handling and timeouts during games', default=False)\n",
    "    parser.add_option('--timeout', dest='timeout', type='int',\n",
    "                      help=default('Maximum length of time an agent can spend computing in a single game'), default=30)\n",
    "\n",
    "    options, otherjunk = parser.parse_args(argv)\n",
    "    if len(otherjunk) != 0:\n",
    "        raise Exception('Command line input not understood: ' + str(otherjunk))\n",
    "    args = dict()\n",
    "\n",
    "    # Fix the random seed\n",
    "    if options.fixRandomSeed:\n",
    "        random.seed('cs188')\n",
    "\n",
    "    # Choose a layout\n",
    "    args['layout'] = layout.getLayout(options.layout)\n",
    "    if args['layout'] == None:\n",
    "        raise Exception(\"The layout \" + options.layout + \" cannot be found\")\n",
    "\n",
    "    # Choose a Pacman agent\n",
    "    noKeyboard = options.gameToReplay == None and (\n",
    "        options.textGraphics or options.quietGraphics)\n",
    "    pacmanType = loadAgent(options.pacman, noKeyboard)\n",
    "    agentOpts = parseAgentArgs(options.agentArgs)\n",
    "    if options.numTraining > 0:\n",
    "        args['numTraining'] = options.numTraining\n",
    "        if 'numTraining' not in agentOpts:\n",
    "            agentOpts['numTraining'] = options.numTraining\n",
    "    pacman = pacmanType(**agentOpts)  # Instantiate Pacman with agentArgs\n",
    "    args['pacman'] = pacman\n",
    "\n",
    "    # Don't display training games\n",
    "    if 'numTrain' in agentOpts:\n",
    "        options.numQuiet = int(agentOpts['numTrain'])\n",
    "        options.numIgnore = int(agentOpts['numTrain'])\n",
    "\n",
    "    # Choose a ghost agent\n",
    "    ghostType = loadAgent(options.ghost, noKeyboard)\n",
    "    args['ghosts'] = [ghostType(i+1) for i in range(options.numGhosts)]\n",
    "\n",
    "    # Choose a display format\n",
    "    if options.quietGraphics:\n",
    "        import textDisplay\n",
    "        args['display'] = textDisplay.NullGraphics()\n",
    "    elif options.textGraphics:\n",
    "        import textDisplay\n",
    "        textDisplay.SLEEP_TIME = options.frameTime\n",
    "        args['display'] = textDisplay.PacmanGraphics()\n",
    "    else:\n",
    "        import graphicsDisplay\n",
    "        args['display'] = graphicsDisplay.PacmanGraphics(\n",
    "            options.zoom, frameTime=options.frameTime)\n",
    "    args['numGames'] = options.numGames\n",
    "    args['record'] = options.record\n",
    "    args['catchExceptions'] = options.catchExceptions\n",
    "    args['timeout'] = options.timeout\n",
    "\n",
    "    # Special case: recorded games don't use the runGames method or args structure\n",
    "    print(\"options.gameToReplay\",options.gameToReplay)\n",
    "    if options.gameToReplay != None:\n",
    "        print('Replaying recorded game %s.' % options.gameToReplay)\n",
    "        import pickle\n",
    "        import sys\n",
    "        #f = open(options.gameToReplay) #maybe was for py2.x?\n",
    "        f = open(options.gameToReplay, 'rb')\n",
    "        try:\n",
    "            recorded = pickle.load(f)\n",
    "        finally:\n",
    "            f.close()\n",
    "        recorded['display'] = args['display']\n",
    "        replayGame(**recorded)\n",
    "        #sys.exit(0)\n",
    "        sys.exit()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def loadAgent(pacman, nographics):\n",
    "    # Looks through all pythonPath Directories for the right module,\n",
    "    pythonPathStr = os.path.expandvars(\"$PYTHONPATH\")\n",
    "    if pythonPathStr.find(';') == -1:\n",
    "        pythonPathDirs = pythonPathStr.split(':')\n",
    "    else:\n",
    "        pythonPathDirs = pythonPathStr.split(';')\n",
    "    pythonPathDirs.append('.')\n",
    "\n",
    "    for moduleDir in pythonPathDirs:\n",
    "        if not os.path.isdir(moduleDir):\n",
    "            continue\n",
    "        moduleNames = [f for f in os.listdir(\n",
    "            moduleDir) if f.endswith('gents.py')]\n",
    "        for modulename in moduleNames:\n",
    "            try:\n",
    "                module = __import__(modulename[:-3])\n",
    "            except ImportError:\n",
    "                continue\n",
    "            if pacman in dir(module):\n",
    "                if nographics and modulename == 'keyboardAgents.py':\n",
    "                    raise Exception(\n",
    "                        'Using the keyboard requires graphics (not text display)')\n",
    "                return getattr(module, pacman)\n",
    "    raise Exception('The agent ' + pacman +\n",
    "                    ' is not specified in any *Agents.py.')\n",
    "\n",
    "\n",
    "def replayGame(layout, actions, display):\n",
    "    import pacmanAgents\n",
    "    import ghostAgents\n",
    "    rules = ClassicGameRules()\n",
    "    agents = [pacmanAgents.GreedyAgent()] + [ghostAgents.RandomGhost(i+1)\n",
    "                                             for i in range(layout.getNumGhosts())]\n",
    "    game = rules.newGame(layout, agents[0], agents[1:], display)\n",
    "    state = game.state\n",
    "    display.initialize(state.data)\n",
    "    print(\"First state:\")\n",
    "    print(state)\n",
    "    for action in actions:\n",
    "        # Execute the action\n",
    "        print(\"Loop state:\")\n",
    "        print(action)\n",
    "        state = state.generateSuccessor(*action)\n",
    "        print(state)\n",
    "        # Change the display\n",
    "        display.update(state.data)\n",
    "        # Allow for game specific conditions (winning, losing, etc.)\n",
    "        rules.process(state, game)\n",
    "\n",
    "    display.finish()\n",
    "\n",
    "\n",
    "def runGames(layout, pacman, ghosts, display, numGames, record, numTraining=0, catchExceptions=False, timeout=30):\n",
    "    import __main__\n",
    "    __main__.__dict__['_display'] = display\n",
    "\n",
    "    rules = ClassicGameRules(timeout)\n",
    "    games = []\n",
    "\n",
    "    for i in range(numGames):\n",
    "        beQuiet = i < numTraining\n",
    "        if beQuiet:\n",
    "                # Suppress output and graphics\n",
    "            import textDisplay\n",
    "            gameDisplay = textDisplay.NullGraphics()\n",
    "            rules.quiet = True\n",
    "        else:\n",
    "            gameDisplay = display\n",
    "            rules.quiet = False\n",
    "        game = rules.newGame(layout, pacman, ghosts,\n",
    "                             gameDisplay, beQuiet, catchExceptions)\n",
    "        game.run()\n",
    "        if not beQuiet:\n",
    "            games.append(game)\n",
    "\n",
    "        if record:\n",
    "            import time\n",
    "            import pickle\n",
    "            folder = 'recorded/'\n",
    "            fname = (folder+'recorded-game-%d' % (i + 1)) + \\\n",
    "                '-'.join([str(t) for t in time.localtime()[1:6]])\n",
    "            #f = file(fname, 'w')#maybe was for py2.x?\n",
    "            f = open(fname, 'wb')\n",
    "            components = {'layout': layout, 'actions': game.moveHistory}\n",
    "            pickle.dump(components, f)\n",
    "            f.close()\n",
    "\n",
    "    if (numGames-numTraining) > 0:\n",
    "        scores = [game.state.getScore() for game in games]\n",
    "        wins = [game.state.isWin() for game in games]\n",
    "        winRate = wins.count(True) / float(len(wins))\n",
    "        print('Average Score:', sum(scores) / float(len(scores)))\n",
    "        print('Scores:       ', ', '.join([str(score) for score in scores]))\n",
    "        print('Win Rate:      %d/%d (%.2f)' %\n",
    "              (wins.count(True), len(wins), winRate))\n",
    "        print('Record:       ', ', '.join(\n",
    "            [['Loss', 'Win'][int(w)] for w in wins]))\n",
    "\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T03:50:18.100667Z",
     "start_time": "2019-06-23T03:50:16.379537Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=148, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n",
      "options.gameToReplay None\n",
      "importing Jupyter notebook from pacman.ipynb\n",
      "options.gameToReplay None\n",
      "Beginning 1 episodes of Training\n",
      "all_q_s_values [34737.7578125  34946.80078125 34528.71484375]\n",
      "all_q_s_values [34757.125      34966.17578125 34548.08203125]\n",
      "Layer 1:\n",
      "tensor([[0.0484, 0.3338, 0.2066,  ..., 0.1545, 0.3720, 0.4925],\n",
      "        [0.9788, 0.4402, 0.9454,  ..., 0.7986, 0.0085, 0.0166],\n",
      "        [0.2035, 0.1102, 0.9266,  ..., 0.5647, 0.0497, 0.1783],\n",
      "        ...,\n",
      "        [0.0646, 0.5421, 0.7634,  ..., 0.8870, 0.4766, 0.5753],\n",
      "        [0.1137, 0.2045, 0.7910,  ..., 0.8883, 0.4770, 0.3822],\n",
      "        [0.5015, 0.7414, 0.8381,  ..., 0.0080, 0.6387, 0.3539]])\n",
      "update:\n",
      "tensor([[ -42.0523,  -42.0523,  -42.0523,  ...,  -42.0523,   -0.0000,\n",
      "         -262.8268],\n",
      "        [ -43.2591,  -43.2591,  -43.2591,  ...,  -43.2591,   -0.0000,\n",
      "         -270.3691],\n",
      "        [ -44.8165,  -44.8165,  -44.8165,  ...,  -44.8165,   -0.0000,\n",
      "         -280.1029],\n",
      "        ...,\n",
      "        [ -44.5747,  -44.5747,  -44.5747,  ...,  -44.5747,   -0.0000,\n",
      "         -278.5916],\n",
      "        [ -45.5563,  -45.5563,  -45.5563,  ...,  -45.5563,   -0.0000,\n",
      "         -284.7270],\n",
      "        [ -44.1117,  -44.1117,  -44.1117,  ...,  -44.1117,   -0.0000,\n",
      "         -275.6980]])\n",
      "Layer 1 - Updated\n",
      "tensor([[-4.2004e+01, -4.1719e+01, -4.1846e+01,  ..., -4.1898e+01,\n",
      "          3.7204e-01, -2.6233e+02],\n",
      "        [-4.2280e+01, -4.2819e+01, -4.2314e+01,  ..., -4.2460e+01,\n",
      "          8.4959e-03, -2.7035e+02],\n",
      "        [-4.4613e+01, -4.4706e+01, -4.3890e+01,  ..., -4.4252e+01,\n",
      "          4.9722e-02, -2.7992e+02],\n",
      "        ...,\n",
      "        [-4.4510e+01, -4.4033e+01, -4.3811e+01,  ..., -4.3688e+01,\n",
      "          4.7663e-01, -2.7802e+02],\n",
      "        [-4.5443e+01, -4.5352e+01, -4.4765e+01,  ..., -4.4668e+01,\n",
      "          4.7705e-01, -2.8434e+02],\n",
      "        [-4.3610e+01, -4.3370e+01, -4.3274e+01,  ..., -4.4104e+01,\n",
      "          6.3873e-01, -2.7534e+02]])\n",
      "all_q_s_values [-12816.53808594 -12816.53808594 -12816.53808594]\n",
      "all_q_s_values [-12816.53808594 -12816.53808594 -12816.53808594]\n",
      "Layer 1:\n",
      "tensor([[-4.2004e+01, -4.1719e+01, -4.1846e+01,  ..., -4.1898e+01,\n",
      "          3.7204e-01, -2.6233e+02],\n",
      "        [-4.2280e+01, -4.2819e+01, -4.2314e+01,  ..., -4.2460e+01,\n",
      "          8.4959e-03, -2.7035e+02],\n",
      "        [-4.4613e+01, -4.4706e+01, -4.3890e+01,  ..., -4.4252e+01,\n",
      "          4.9722e-02, -2.7992e+02],\n",
      "        ...,\n",
      "        [-4.4510e+01, -4.4033e+01, -4.3811e+01,  ..., -4.3688e+01,\n",
      "          4.7663e-01, -2.7802e+02],\n",
      "        [-4.5443e+01, -4.5352e+01, -4.4765e+01,  ..., -4.4668e+01,\n",
      "          4.7705e-01, -2.8434e+02],\n",
      "        [-4.3610e+01, -4.3370e+01, -4.3274e+01,  ..., -4.4104e+01,\n",
      "          6.3873e-01, -2.7534e+02]])\n",
      "update:\n",
      "tensor([[ 15.6041,  15.6041,  15.6041,  ...,  15.6041,   0.0000,  97.5258],\n",
      "        [ 16.0519,  16.0519,  16.0519,  ...,  16.0519,   0.0000, 100.3245],\n",
      "        [ 16.6298,  16.6298,  16.6298,  ...,  16.6298,   0.0000, 103.9363],\n",
      "        ...,\n",
      "        [ 16.5401,  16.5401,  16.5401,  ...,  16.5401,   0.0000, 103.3756],\n",
      "        [ 16.9044,  16.9044,  16.9044,  ...,  16.9044,   0.0000, 105.6522],\n",
      "        [ 16.3683,  16.3683,  16.3683,  ...,  16.3683,   0.0000, 102.3019]])\n",
      "Layer 1 - Updated\n",
      "tensor([[-2.6400e+01, -2.6114e+01, -2.6242e+01,  ..., -2.6294e+01,\n",
      "          3.7204e-01, -1.6481e+02],\n",
      "        [-2.6228e+01, -2.6767e+01, -2.6262e+01,  ..., -2.6409e+01,\n",
      "          8.4959e-03, -1.7003e+02],\n",
      "        [-2.7983e+01, -2.8076e+01, -2.7260e+01,  ..., -2.7622e+01,\n",
      "          4.9722e-02, -1.7599e+02],\n",
      "        ...,\n",
      "        [-2.7970e+01, -2.7492e+01, -2.7271e+01,  ..., -2.7148e+01,\n",
      "          4.7663e-01, -1.7464e+02],\n",
      "        [-2.8538e+01, -2.8447e+01, -2.7861e+01,  ..., -2.7764e+01,\n",
      "          4.7705e-01, -1.7869e+02],\n",
      "        [-2.7242e+01, -2.7002e+01, -2.6905e+01,  ..., -2.7735e+01,\n",
      "          6.3873e-01, -1.7304e+02]])\n",
      "all_q_s_values [-2.71589376e+08 -2.71589376e+08 -2.71589376e+08]\n",
      "Layer 1:\n",
      "tensor([[-2.6400e+01, -2.6114e+01, -2.6242e+01,  ..., -2.6294e+01,\n",
      "          3.7204e-01, -1.6481e+02],\n",
      "        [-2.6228e+01, -2.6767e+01, -2.6262e+01,  ..., -2.6409e+01,\n",
      "          8.4959e-03, -1.7003e+02],\n",
      "        [-2.7983e+01, -2.8076e+01, -2.7260e+01,  ..., -2.7622e+01,\n",
      "          4.9722e-02, -1.7599e+02],\n",
      "        ...,\n",
      "        [-2.7970e+01, -2.7492e+01, -2.7271e+01,  ..., -2.7148e+01,\n",
      "          4.7663e-01, -1.7464e+02],\n",
      "        [-2.8538e+01, -2.8447e+01, -2.7861e+01,  ..., -2.7764e+01,\n",
      "          4.7705e-01, -1.7869e+02],\n",
      "        [-2.7242e+01, -2.7002e+01, -2.6905e+01,  ..., -2.7735e+01,\n",
      "          6.3873e-01, -1.7304e+02]])\n",
      "update:\n",
      "tensor([[ 328354.3438,  328354.3438,  328354.3438,  ...,  328354.3438,\n",
      "               0.0000, 2052214.3750],\n",
      "        [ 337777.0625,  337777.0625,  337777.0625,  ...,  337777.0625,\n",
      "               0.0000, 2111106.5000],\n",
      "        [ 349937.5938,  349937.5938,  349937.5938,  ...,  349937.5938,\n",
      "               0.0000, 2187110.0000],\n",
      "        ...,\n",
      "        [ 348049.5938,  348049.5938,  348049.5938,  ...,  348049.5938,\n",
      "               0.0000, 2175309.7500],\n",
      "        [ 355714.6562,  355714.6562,  355714.6562,  ...,  355714.6562,\n",
      "               0.0000, 2223216.5000],\n",
      "        [ 344434.5625,  344434.5625,  344434.5625,  ...,  344434.5625,\n",
      "               0.0000, 2152716.0000]])\n",
      "Layer 1 - Updated\n",
      "tensor([[3.2833e+05, 3.2833e+05, 3.2833e+05,  ..., 3.2833e+05, 3.7204e-01,\n",
      "         2.0520e+06],\n",
      "        [3.3775e+05, 3.3775e+05, 3.3775e+05,  ..., 3.3775e+05, 8.4959e-03,\n",
      "         2.1109e+06],\n",
      "        [3.4991e+05, 3.4991e+05, 3.4991e+05,  ..., 3.4991e+05, 4.9722e-02,\n",
      "         2.1869e+06],\n",
      "        ...,\n",
      "        [3.4802e+05, 3.4802e+05, 3.4802e+05,  ..., 3.4802e+05, 4.7663e-01,\n",
      "         2.1751e+06],\n",
      "        [3.5569e+05, 3.5569e+05, 3.5569e+05,  ..., 3.5569e+05, 4.7705e-01,\n",
      "         2.2230e+06],\n",
      "        [3.4441e+05, 3.4441e+05, 3.4441e+05,  ..., 3.4441e+05, 6.3873e-01,\n",
      "         2.1525e+06]])\n",
      "all_q_s_values [-2.55646520e+27 -2.61247099e+27 -2.50045941e+27]\n",
      "all_q_s_values [-2.54571178e+27 -2.60171757e+27 -2.48970658e+27]\n",
      "Layer 1:\n",
      "tensor([[3.2833e+05, 3.2833e+05, 3.2833e+05,  ..., 3.2833e+05, 3.7204e-01,\n",
      "         2.0520e+06],\n",
      "        [3.3775e+05, 3.3775e+05, 3.3775e+05,  ..., 3.3775e+05, 8.4959e-03,\n",
      "         2.1109e+06],\n",
      "        [3.4991e+05, 3.4991e+05, 3.4991e+05,  ..., 3.4991e+05, 4.9722e-02,\n",
      "         2.1869e+06],\n",
      "        ...,\n",
      "        [3.4802e+05, 3.4802e+05, 3.4802e+05,  ..., 3.4802e+05, 4.7663e-01,\n",
      "         2.1751e+06],\n",
      "        [3.5569e+05, 3.5569e+05, 3.5569e+05,  ..., 3.5569e+05, 4.7705e-01,\n",
      "         2.2230e+06],\n",
      "        [3.4441e+05, 3.4441e+05, 3.4441e+05,  ..., 3.4441e+05, 6.3873e-01,\n",
      "         2.1525e+06]])\n",
      "update:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "Layer 1 - Updated\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "all_q_s_values [nan nan nan]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7b723eb408ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m            \"-x1\", \"-n1\", \"-k1\", \"-gRandomGhost\",\"-lsmallClassic\"]\n\u001b[1;32m      7\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadCommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get game components based on options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrunGames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-33984fb40f7a>\u001b[0m in \u001b[0;36mrunGames\u001b[0;34m(layout, pacman, ghosts, display, numGames, record, numTraining, catchExceptions, timeout)\u001b[0m\n\u001b[1;32m    694\u001b[0m         game = rules.newGame(layout, pacman, ghosts,\n\u001b[1;32m    695\u001b[0m                              gameDisplay, beQuiet, catchExceptions)\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbeQuiet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mgames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tpfinal-procesos-markovianos/cs188x-spring2019/game.ipynb\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m~/tpfinal-procesos-markovianos/cs188x-spring2019/qlearningAgents.py\u001b[0m in \u001b[0;36mgetAction\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0;31m# Act greedly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;31m#action = self.computeActionFromNN(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeActionFromNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0;31m#print(\"segunda que devuelve action:\", action, type(action))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Leave trace for calculating grad on update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tpfinal-procesos-markovianos/cs188x-spring2019/qlearningAgents.py\u001b[0m in \u001b[0;36mcomputeActionFromNN\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0;31m#all_q_s_values = [sum(self.net(torch.Tensor(np.concatenate((numer_state, actions[a]))))) for a in legalActions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all_q_s_values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_q_s_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mbest_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_q_s_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegalActions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_action\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;31m#print(\"action returned\", str(action), type(str(action)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tpfinal-procesos-markovianos/cs188x-spring2019/qlearningAgents.py\u001b[0m in \u001b[0;36mrandom_argmax\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     41\u001b[0m        chooses and returns one randomly\"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "#options = [\"-pApproximateQAgent\", \"-x2000\", \"-n2003\", \"-lsmallClassic\"]#\"-gDirectionalGhost\"\n",
    "# Tabular case:\n",
    "#options = [\"-pPacmanQAgent\", \"-x2000\", \"-n2003\", \"-lsmallGrid\"] # -x2000 to get a good win rate\n",
    "# NN Agent\n",
    "options = [\"-pNNQAgent\", \"-aextractor=SimpleExtractor\",\n",
    "           \"-x1\", \"-n1\", \"-k1\", \"-gRandomGhost\",\"-lsmallClassicMod\"]\n",
    "args = readCommand(options)  # Get game components based on options\n",
    "runGames(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T00:34:33.150903Z",
     "start_time": "2019-06-23T00:34:33.139748Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q (table) size: 45\r",
      "Q (table) size: 46\r"
     ]
    }
   ],
   "source": [
    "print(\"Q (table) size: \"+str(45), end=\"\\r\")\n",
    "print(\"Q (table) size: \"+str(46), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T00:34:33.175959Z",
     "start_time": "2019-06-23T00:34:33.153198Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# From layout of chars to layout of numbers\n",
    "# Beware: This will be painful to see\n",
    "def ascii_state_to_numeric_state(ascii_state):\n",
    "    str_state = str(ascii_state)\n",
    "    score_pos = str(str_state).find(\"Score: \")\n",
    "    ascii_map = str(str_state)[:score_pos-1]\n",
    "\n",
    "    numer_map = np.ndarray(len(ascii_map)+1)\n",
    "    for i, c in enumerate(ascii_map):\n",
    "        if c==' ':\n",
    "            numer_map[i] = 1\n",
    "            continue\n",
    "        if c=='%':\n",
    "            numer_map[i] = 2\n",
    "            continue\n",
    "        if c=='.':\n",
    "            numer_map[i] = 3\n",
    "            continue\n",
    "        if c=='\\n':\n",
    "            numer_map[i] = 4\n",
    "            continue\n",
    "        if c=='G':\n",
    "            numer_map[i] = 5\n",
    "            continue\n",
    "        if c=='o':\n",
    "            numer_map[i] = 6\n",
    "            continue\n",
    "        # Pacman dirs\n",
    "        if c=='<':\n",
    "            numer_map[i] = 7\n",
    "            continue\n",
    "        if c=='>':\n",
    "            numer_map[i] = 8\n",
    "            continue\n",
    "        if c=='^':\n",
    "            numer_map[i] = 9\n",
    "            continue\n",
    "        if c=='v':\n",
    "            numer_map[i] = 10\n",
    "            continue\n",
    "    numer_map /= 15.0\n",
    "    #last array position will contain the score\n",
    "    numer_map[-1] = float(str_state[score_pos+7:])/3000\n",
    "    return numer_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T00:34:33.194869Z",
     "start_time": "2019-06-23T00:34:33.179087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascii map:\n",
      "%%%%%%%\n",
      "%     %\n",
      "% %%% %\n",
      "% %.  %\n",
      "% %%% %\n",
      "%.  G %\n",
      "%%%%%%%\n",
      "Score: -547\n",
      "\n",
      "Numeric map:\n",
      "[ 0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333\n",
      "  0.13333333  0.26666667  0.13333333  0.06666667  0.06666667  0.06666667\n",
      "  0.06666667  0.06666667  0.13333333  0.26666667  0.13333333  0.06666667\n",
      "  0.13333333  0.13333333  0.13333333  0.06666667  0.13333333  0.26666667\n",
      "  0.13333333  0.06666667  0.13333333  0.2         0.06666667  0.06666667\n",
      "  0.13333333  0.26666667  0.13333333  0.06666667  0.13333333  0.13333333\n",
      "  0.13333333  0.06666667  0.13333333  0.26666667  0.13333333  0.2\n",
      "  0.06666667  0.06666667  0.33333333  0.06666667  0.13333333  0.26666667\n",
      "  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333  0.13333333\n",
      "  0.13333333 -0.18233333]\n",
      "Score normalizado: -0.18233333333333332\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "numer_map = ascii_state_to_numeric_state(SOME_GLOBAL_STATE)\n",
    "ascii_map = SOME_GLOBAL_STATE\n",
    "print (\"Ascii map:\")\n",
    "print (ascii_map)\n",
    "print (\"Numeric map:\")\n",
    "print (numer_map)\n",
    "print(\"Score normalizado:\", numer_map[-1])\n",
    "print(len(numer_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T00:34:33.214942Z",
     "start_time": "2019-06-23T00:34:33.196795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13333333,  0.13333333,  0.13333333,  0.13333333,  0.13333333,\n",
       "        0.13333333,  0.13333333,  0.26666667,  0.13333333,  0.06666667,\n",
       "        0.06666667,  0.06666667,  0.06666667,  0.06666667,  0.13333333,\n",
       "        0.26666667,  0.13333333,  0.06666667,  0.13333333,  0.13333333,\n",
       "        0.13333333,  0.06666667,  0.13333333,  0.26666667,  0.13333333,\n",
       "        0.06666667,  0.13333333,  0.2       ,  0.06666667,  0.06666667,\n",
       "        0.13333333,  0.26666667,  0.13333333,  0.06666667,  0.13333333,\n",
       "        0.13333333,  0.13333333,  0.06666667,  0.13333333,  0.26666667,\n",
       "        0.13333333,  0.2       ,  0.06666667,  0.06666667,  0.33333333,\n",
       "        0.06666667,  0.13333333,  0.26666667,  0.13333333,  0.13333333,\n",
       "        0.13333333,  0.13333333,  0.13333333,  0.13333333,  0.13333333,\n",
       "       -0.18233333,  2.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((numer_map, [2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T00:34:33.318702Z",
     "start_time": "2019-06-23T00:34:33.218849Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GameState' object has no attribute 'inspect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c15621ff2299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSOME_GLOBAL_STATE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GameState' object has no attribute 'inspect'"
     ]
    }
   ],
   "source": [
    "SOME_GLOBAL_STATE.inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T00:34:33.321609Z",
     "start_time": "2019-06-23T00:34:11.160Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     \"\"\"\n",
    "#     The main function called when pacman.py is run\n",
    "#     from the command line:\n",
    "\n",
    "#     > python pacman.py\n",
    "\n",
    "#     See the usage string for more details.\n",
    "\n",
    "#     > python pacman.py --help\n",
    "#     \"\"\"\n",
    "#     args = readCommand(sys.argv[1:])  # Get game components based on input\n",
    "#     runGames(**args)\n",
    "\n",
    "#     # import cProfile\n",
    "#     # cProfile.run(\"runGames( **args )\")\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
